{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6508713a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# === 1. Load dan filter data ===\n",
    "df = pd.read_csv('dataset/ikn.csv')\n",
    "keywords = ['ikn', 'nusantara', 'ibu kota', 'ibukota', 'pemindahan', 'perpindahan']\n",
    "filtered_df = df[df['full_text'].str.contains('|'.join(keywords), case=False)].copy()\n",
    "\n",
    "filtered_df = filtered_df[filtered_df['full_text'].str.strip() != '']\n",
    "filtered_df = filtered_df.drop_duplicates(subset='full_text')\n",
    "filtered_df['full_text'] = filtered_df['full_text'].str.replace(r'http\\S+', '', regex=True)\n",
    "filtered_df['word_count'] = filtered_df['full_text'].apply(lambda x: len(x.split()))\n",
    "filtered_df = filtered_df[filtered_df['word_count'] >= 5]\n",
    "filtered_df.drop(columns=['word_count'], inplace=True)\n",
    "\n",
    "# === 2. Preprocessing ===\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "stop_words = set(stopwords.words('indonesian'))\n",
    "tambahan_stop = {\n",
    "    'gw', 'gue', 'gua', 'lu', 'loe', 'lo', 'elu', 'nya', 'ya', 'aja', 'sih', 'lah', 'deh', 'dong',\n",
    "    'kok', 'nih', 'tuh', 'lagi', 'kayak', 'gak', 'ga', 'nggak', 'ngga', 'yg', 'yang', 'saya', 'kamu'\n",
    "}\n",
    "stop_words.update(tambahan_stop)\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.strip()\n",
    "    text = re.sub(r'\\bgw\\b|\\bgue\\b|\\bgua\\b', 'saya', text)\n",
    "    text = re.sub(r'\\blu\\b|\\bloe\\b|\\belo\\b|\\belu\\b', 'kamu', text)\n",
    "    text = re.sub(r'\\bnggak\\b|\\bngga\\b|\\bga\\b|\\bgak\\b', 'tidak', text)\n",
    "    text = stemmer.stem(text)\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "filtered_df['cleaned'] = filtered_df['full_text'].apply(clean_text)\n",
    "\n",
    "# === 2.1 Perkaya dan Gabungkan Kamus Kata Dasar ===\n",
    "with open('sastrawi/kata-dasar.txt', 'r', encoding='utf-8') as f:\n",
    "    kamus_sastrawi = set(f.read().splitlines())\n",
    "\n",
    "pos_words = [\n",
    "    'baik', 'bagus', 'mendukung', 'hebat', 'mantap', 'setuju',\n",
    "    'top', 'luar biasa', 'sip', 'apresiasi', 'bangga',\n",
    "    'kemajuan', 'ramah', 'berkelanjutan', 'peluang', 'strategis',\n",
    "    'pertumbuhan', 'investasi', 'unggulan', 'mendorong', 'semangat',\n",
    "    'kondusif', 'cocok', 'positif', 'cerah', 'maju', 'bermanfaat',\n",
    "    'berkembang', 'terdepan', 'mendorong', 'sukses', 'membangun'\n",
    "]\n",
    "neg_words = [\n",
    "    'buruk', 'jelek', 'korupsi', 'parah', 'gagal', 'tolak',\n",
    "    'tidak setuju', 'menolak', 'ancur', 'bubar', 'kritik', 'macet',\n",
    "    'tidak ramah', 'tidak layak', 'tidak manusiawi', 'tidak cocok',\n",
    "    'bohong', 'salah', 'mundur', 'krisis', 'masalah', 'keluhan',\n",
    "    'cacat', 'curang', 'konflik', 'resah'\n",
    "]\n",
    "\n",
    "pos_words_stemmed = [stemmer.stem(w.lower()) for w in pos_words]\n",
    "neg_words_stemmed = [stemmer.stem(w.lower()) for w in neg_words]\n",
    "\n",
    "kamus_kata = kamus_sastrawi.union(set(pos_words_stemmed)).union(set(neg_words_stemmed))\n",
    "\n",
    "def hapus_kata_non_kamus(text):\n",
    "    filtered_words = [word for word in text.split() if word in kamus_kata]\n",
    "    if len(filtered_words) == 0:\n",
    "        return text\n",
    "    else:\n",
    "        return ' '.join(filtered_words)\n",
    "\n",
    "filtered_df['final_cleaned'] = filtered_df['cleaned'].apply(hapus_kata_non_kamus)\n",
    "\n",
    "# === 3. Sentiment label dari fungsi simple_sentiment ===\n",
    "def simple_sentiment(text):\n",
    "    score = 0\n",
    "    for word in text.split():\n",
    "        if word in pos_words_stemmed:\n",
    "            score += 1\n",
    "        elif word in neg_words_stemmed:\n",
    "            score -= 1\n",
    "    return 'positif' if score > 0 else 'negatif'\n",
    "\n",
    "filtered_df['sentiment'] = filtered_df['final_cleaned'].apply(simple_sentiment)\n",
    "\n",
    "# === 4. Simpan data bersih ===\n",
    "filtered_df[['full_text', 'final_cleaned', 'sentiment']].to_csv('dataset/data_bersih_sentimen.csv', index=False)\n",
    "print(\"âœ… Data berhasil disimpan ke dataset/data_bersih_sentimen.csv\")\n",
    "\n",
    "# === 5. Label encoding ===\n",
    "le = LabelEncoder()\n",
    "filtered_df['label'] = le.fit_transform(filtered_df['sentiment'])\n",
    "\n",
    "# === 6. TF-IDF + Naive Bayes ===\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "X = filtered_df['final_cleaned']\n",
    "y = filtered_df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# === 7. Evaluasi model ===\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Akurasi:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "labels = le.transform(['negatif', 'positif'])\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred, labels=labels))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, labels=labels, target_names=['negatif', 'positif'], zero_division=1))\n",
    "\n",
    "# === 8. Visualisasi distribusi sentimen ===\n",
    "filtered_df['sentiment'].value_counts().plot(kind='bar', color=['red', 'green'])\n",
    "plt.title('Distribusi Sentimen')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
